{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "import os\n",
    "import torchaudio\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Wav2Vec2Model, Wave2Vec2Processor, Trainer, TrainingArguments, Wave2Vec2ForSequenceClassification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "labels = []\n",
    "\n",
    "for dirname, _, filenames in os.walk(\"/input\"):\n",
    "    for filename in filenames:\n",
    "        paths.append(os.path.join(dirname, filename))\n",
    "        label = filename.split(\"_\")[-1]\n",
    "        label = label.split(\".\")[0]\n",
    "        labels.append(label.lower())\n",
    "    \n",
    "    if len(paths) == 2800:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"audio_paths\"] = paths\n",
    "df[\"labels\"] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x=\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def waveplot(data, sr, emotion):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.title(emotion, size=20)\n",
    "    librosa.display.waveshow(data, sr=sr)\n",
    "    plt.show()\n",
    "\n",
    "def spectogram(data, sr, emotion):\n",
    "    x = librosa.stft(data)\n",
    "    xdb = librosa.aplitude_to_db(abs(x))\n",
    "    plt.figure(figsize=(11,4))\n",
    "    plt.title(emotion, size=20)\n",
    "    librosa.display.specshow(xdb, sr=sr, x_axis=\"time\", y_axis=\"hz\")\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = \"fear\"\n",
    "path = np.array(df[\"audio_paths\"][df[\"labels\"]==emotion])[0]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "waveplot(data, sampling_rate, emotion)\n",
    "spectogram(data, sampling_rate, emotion)\n",
    "Audio(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
